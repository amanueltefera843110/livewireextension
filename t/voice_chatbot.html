<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice AI Chatbot</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            width: 100%;
            max-width: 800px;
            height: 90vh;
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px 30px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        .header h1 {
            font-size: 24px;
            font-weight: 600;
        }

        .context-indicator {
            background: rgba(255,255,255,0.2);
            padding: 5px 12px;
            border-radius: 20px;
            font-size: 12px;
            display: none;
        }

        .context-indicator.active {
            display: block;
            background: rgba(76,175,80,0.9);
        }

        .chat-area {
            flex: 1;
            overflow-y: auto;
            padding: 20px;
            background: #f5f5f5;
        }

        .message {
            margin-bottom: 20px;
            display: flex;
            animation: slideIn 0.3s ease;
        }

        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .message.user {
            justify-content: flex-end;
        }

        .message-content {
            max-width: 70%;
            padding: 12px 18px;
            border-radius: 18px;
            word-wrap: break-word;
        }

        .message.user .message-content {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-bottom-right-radius: 4px;
        }

        .message.assistant .message-content {
            background: white;
            color: #333;
            border-bottom-left-radius: 4px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        .controls {
            padding: 20px;
            background: white;
            border-top: 1px solid #e0e0e0;
        }

        .upload-section {
            margin-bottom: 15px;
            padding-bottom: 15px;
            border-bottom: 1px solid #f0f0f0;
        }

        .file-input-wrapper {
            display: flex;
            gap: 10px;
            align-items: center;
        }

        .file-input-wrapper input[type="file"] {
            flex: 1;
            padding: 8px;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            font-size: 14px;
        }

        .btn {
            padding: 10px 20px;
            border: none;
            border-radius: 8px;
            font-size: 14px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            display: inline-flex;
            align-items: center;
            gap: 8px;
        }

        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .btn-primary {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .btn-primary:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102,126,234,0.4);
        }

        .btn-secondary {
            background: #f0f0f0;
            color: #333;
        }

        .btn-secondary:hover:not(:disabled) {
            background: #e0e0e0;
        }

        .btn-danger {
            background: #f44336;
            color: white;
        }

        .voice-section {
            display: flex;
            gap: 10px;
            align-items: center;
        }

        .voice-btn {
            width: 60px;
            height: 60px;
            border-radius: 50%;
            border: none;
            font-size: 24px;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .voice-btn.recording {
            background: #f44336;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0%, 100% {
                box-shadow: 0 0 0 0 rgba(244,67,54,0.7);
            }
            50% {
                box-shadow: 0 0 0 15px rgba(244,67,54,0);
            }
        }

        .status {
            padding: 10px;
            border-radius: 8px;
            margin-top: 10px;
            font-size: 14px;
            display: none;
        }

        .status.show {
            display: block;
        }

        .status.success {
            background: #c8e6c9;
            color: #2e7d32;
        }

        .status.error {
            background: #ffcdd2;
            color: #c62828;
        }

        .status.info {
            background: #bbdefb;
            color: #1565c0;
        }

        .typing-indicator {
            display: none;
            padding: 15px;
            margin-bottom: 10px;
        }

        .typing-indicator.show {
            display: flex;
        }

        .typing-indicator span {
            width: 8px;
            height: 8px;
            background: #999;
            border-radius: 50%;
            margin: 0 2px;
            animation: typing 1.4s infinite;
        }

        .typing-indicator span:nth-child(2) {
            animation-delay: 0.2s;
        }

        .typing-indicator span:nth-child(3) {
            animation-delay: 0.4s;
        }

        @keyframes typing {
            0%, 60%, 100% {
                transform: translateY(0);
            }
            30% {
                transform: translateY(-10px);
            }
        }

        .clear-btn {
            font-size: 12px;
            padding: 6px 12px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üé§ Voice AI Chatbot</h1>
            <div class="context-indicator" id="contextIndicator">üìÑ PDF Loaded</div>
        </div>

        <div class="chat-area" id="chatArea">
            <div class="message assistant">
                <div class="message-content">
                    Hello! I'm your AI assistant. Upload a PDF to give me context, or just start talking to me!
                </div>
            </div>
        </div>

        <div class="typing-indicator" id="typingIndicator">
            <span></span><span></span><span></span>
        </div>

        <div class="controls">
            <div class="upload-section">
                <div class="file-input-wrapper">
                    <input type="file" id="pdfFile" accept=".pdf">
                    <button class="btn btn-primary" id="uploadBtn" onclick="uploadPDF()">
                        üì§ Upload PDF
                    </button>
                    <button class="btn btn-danger clear-btn" onclick="clearContext()">
                        üóëÔ∏è Clear
                    </button>
                </div>
            </div>

            <div class="voice-section">
                <button class="voice-btn btn-primary" id="voiceBtn" onclick="toggleRecording()">
                    üé§
                </button>
                <div style="flex: 1;">
                    <div style="font-size: 12px; color: #666; margin-bottom: 5px;">
                        Click microphone to speak
                    </div>
                    <label style="display: flex; align-items: center; gap: 8px; font-size: 14px;">
                        <input type="checkbox" id="autoSpeak" checked>
                        Auto-speak responses
                    </label>
                </div>
            </div>

            <div class="status" id="status"></div>
        </div>
    </div>

    <script>
        let isRecording = false;
        let mediaRecorder;
        let audioChunks = [];
        let speechSynthesis = window.speechSynthesis;

        function showStatus(message, type = 'info') {
            const status = document.getElementById('status');
            status.textContent = message;
            status.className = `status show ${type}`;
            setTimeout(() => {
                status.classList.remove('show');
            }, 3000);
        }

        function addMessage(text, isUser = false) {
            const chatArea = document.getElementById('chatArea');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${isUser ? 'user' : 'assistant'}`;
            messageDiv.innerHTML = `<div class="message-content">${text}</div>`;
            chatArea.appendChild(messageDiv);
            chatArea.scrollTop = chatArea.scrollHeight;
        }

        function showTyping(show) {
            document.getElementById('typingIndicator').classList.toggle('show', show);
        }

        function speak(text) {
            if (!document.getElementById('autoSpeak').checked) return;
            
            speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.rate = 0.9;
            utterance.pitch = 1;
            utterance.volume = 1;
            speechSynthesis.speak(utterance);
        }

        async function uploadPDF() {
            const fileInput = document.getElementById('pdfFile');
            const file = fileInput.files[0];

            if (!file) {
                showStatus('Please select a PDF file first', 'error');
                return;
            }

            const formData = new FormData();
            formData.append('file', file);

            showStatus('Uploading and processing PDF...', 'info');

            try {
                const response = await fetch('/upload_pdf', {
                    method: 'POST',
                    body: formData
                });

                const data = await response.json();

                if (data.status === 'success') {
                    showStatus(data.message, 'success');
                    document.getElementById('contextIndicator').classList.add('active');
                    
                    if (data.summary) {
                        addMessage(`PDF Summary: ${data.summary}`);
                        speak(`I've loaded your PDF. ${data.summary}`);
                    }
                } else {
                    showStatus(data.message, 'error');
                }
            } catch (error) {
                showStatus('Failed to upload PDF', 'error');
                console.error(error);
            }
        }

        async function clearContext() {
            if (!confirm('Clear PDF context and conversation history?')) return;

            try {
                await fetch('/clear_context', { method: 'POST' });
                document.getElementById('contextIndicator').classList.remove('active');
                document.getElementById('chatArea').innerHTML = `
                    <div class="message assistant">
                        <div class="message-content">
                            Context cleared! Upload a new PDF or start a fresh conversation.
                        </div>
                    </div>
                `;
                showStatus('Context cleared', 'success');
            } catch (error) {
                showStatus('Failed to clear context', 'error');
            }
        }

        async function toggleRecording() {
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    await processAudio(audioBlob);
                    
                    stream.getTracks().forEach(track => track.stop());
                };

                mediaRecorder.start();
                isRecording = true;
                document.getElementById('voiceBtn').classList.add('recording');
                document.getElementById('voiceBtn').textContent = '‚èπÔ∏è';
                showStatus('Recording... Click again to stop', 'info');

            } catch (error) {
                showStatus('Microphone access denied', 'error');
                console.error(error);
            }
        }

        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;
                document.getElementById('voiceBtn').classList.remove('recording');
                document.getElementById('voiceBtn').textContent = 'üé§';
                showStatus('Processing...', 'info');
            }
        }

        async function processAudio(audioBlob) {
            try {
                const formData = new FormData();
                formData.append('file', audioBlob, 'audio.wav');

                const transcribeResponse = await fetch('/transcribe_audio', {
                    method: 'POST',
                    body: formData
                });

                const transcribeData = await transcribeResponse.json();

                if (transcribeData.status !== 'success') {
                    showStatus('Transcription failed', 'error');
                    return;
                }

                const userText = transcribeData.text;
                addMessage(userText, true);

                showTyping(true);
                
                const chatFormData = new FormData();
                chatFormData.append('message', userText);

                const chatResponse = await fetch('/chat', {
                    method: 'POST',
                    body: chatFormData
                });

                const chatData = await chatResponse.json();
                showTyping(false);

                if (chatData.status === 'success') {
                    addMessage(chatData.response);
                    speak(chatData.response);
                    showStatus('Done!', 'success');
                } else {
                    showStatus('Chat failed: ' + chatData.message, 'error');
                }

            } catch (error) {
                showTyping(false);
                showStatus('Error processing audio', 'error');
                console.error(error);
            }
        }

        window.addEventListener('beforeunload', () => {
            speechSynthesis.cancel();
        });
    </script>
</body>
</html>